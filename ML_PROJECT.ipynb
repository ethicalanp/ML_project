{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uditi-12/ML_project/blob/main/ML_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCz9T9k7eswa",
        "outputId": "58294bc4-caa5-49fe-8afb-69765a0e08f9"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(('/content/drive/MyDrive/VIT/Sem_5(1)/B-ML (1)/LABS/dataset/train_MachineLearningCVE.csv'), skipinitialspace=True, nrows = 10000)\n",
        "df_test = pd.read_csv(('/content/drive/MyDrive/VIT/Sem_5(1)/B-ML (1)/LABS/dataset/test_MachineLearningCVE.csv'), skipinitialspace=True, nrows = 10000)"
      ],
      "metadata": {
        "id": "_jIzhqaB5esN"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_test.Label.unique()"
      ],
      "metadata": {
        "id": "CN8MmvNS5txd"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_train.Label.unique()"
      ],
      "metadata": {
        "id": "rABwEOp05r6S"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_train, df_test], axis=0, copy=True)\n",
        "df.Label.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeFKWplp5xJE",
        "outputId": "15f30203-6749-45b7-d62d-91176ecbae86"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 10,  4,  7,  3,  5,  6, 11,  1, 12, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df.head"
      ],
      "metadata": {
        "id": "3ieKVE2g53ax"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna()"
      ],
      "metadata": {
        "id": "UA5YfWxz6Jge"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.dtypes"
      ],
      "metadata": {
        "id": "iKXSPYGp6FTD"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['Label'].value_counts(sort=True)"
      ],
      "metadata": {
        "id": "zEcT2RTS5--J"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1)\n",
        "x = df.iloc[:, df.columns != 'Label']\n",
        "y = df[['Label']].to_numpy()"
      ],
      "metadata": {
        "id": "e5GIPyzr6RV-"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(x)"
      ],
      "metadata": {
        "id": "QEI7g0ux6XUV"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=1, stratify=y)"
      ],
      "metadata": {
        "id": "FQow3-QB6aQf"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE \n",
        "k=2\n",
        "sm = SMOTE(k_neighbors=k, random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel()) "
      ],
      "metadata": {
        "id": "OzXXPWoc68IX"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "_2Uvp7YrQKDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24e6017-4e57-4f4f-fe07-591bf4fd8168"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18000, 78)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "04yYvclH_ogC",
        "outputId": "45f6ba9c-893d-493f-d5c5-332c739bfb61"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Destination Port  Flow Duration  Total Fwd Packets  \\\n",
              "1191               443      5735211.0                  9   \n",
              "8516                53        50299.0                  2   \n",
              "5975                53        26691.0                  2   \n",
              "8257               443    115409745.0                 44   \n",
              "6007                53        48366.0                  1   \n",
              "...                ...            ...                ...   \n",
              "1493                80     99765580.0                  7   \n",
              "8519               443    113153586.0                 40   \n",
              "3302                53          169.0                  2   \n",
              "3988               443       136364.0                 14   \n",
              "4873             52188            1.0                  2   \n",
              "\n",
              "      Total Backward Packets  Total Length of Fwd Packets  \\\n",
              "1191                       6                          350   \n",
              "8516                       2                           64   \n",
              "5975                       2                           68   \n",
              "8257                      57                          743   \n",
              "6007                       1                           55   \n",
              "...                      ...                          ...   \n",
              "1493                       6                          368   \n",
              "8519                      44                         1628   \n",
              "3302                       2                           94   \n",
              "3988                      10                          847   \n",
              "4873                       0                           12   \n",
              "\n",
              "      Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
              "1191                         4867                    193   \n",
              "8516                          204                     32   \n",
              "5975                          158                     34   \n",
              "8257                        76082                    354   \n",
              "6007                           93                     55   \n",
              "...                           ...                    ...   \n",
              "1493                        11595                    368   \n",
              "8519                        47059                    336   \n",
              "3302                          206                     47   \n",
              "3988                         8831                    373   \n",
              "4873                            0                      6   \n",
              "\n",
              "      Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
              "1191                      0               38.888889              71.129186   \n",
              "8516                     32               32.000000               0.000000   \n",
              "5975                     34               34.000000               0.000000   \n",
              "8257                      0               16.886364              64.409741   \n",
              "6007                     55               55.000000               0.000000   \n",
              "...                     ...                     ...                    ...   \n",
              "1493                      0               52.571429             139.090926   \n",
              "8519                      0               40.700000             103.236398   \n",
              "3302                     47               47.000000               0.000000   \n",
              "3988                      0               60.500000             116.258829   \n",
              "4873                      6                6.000000               0.000000   \n",
              "\n",
              "      ...  act_data_pkt_fwd  min_seg_size_forward   Active Mean   Active Std  \\\n",
              "1191  ...                 3                  32.0  155518.00000       0.0000   \n",
              "8516  ...                 1                  20.0       0.00000       0.0000   \n",
              "5975  ...                 1                  32.0       0.00000       0.0000   \n",
              "8257  ...                 4                  32.0   42871.27273   35355.2571   \n",
              "6007  ...                 0                  20.0       0.00000       0.0000   \n",
              "...   ...               ...                   ...           ...          ...   \n",
              "1493  ...                 1                  32.0     379.00000       0.0000   \n",
              "8519  ...                 6                  32.0  268192.09090  736552.1540   \n",
              "3302  ...                 1                  20.0       0.00000       0.0000   \n",
              "3988  ...                 6                  32.0       0.00000       0.0000   \n",
              "4873  ...                 1                  20.0       0.00000       0.0000   \n",
              "\n",
              "      Active Max  Active Min   Idle Mean      Idle Std  Idle Max  Idle Min  \n",
              "1191      155518      155518   5579690.0      0.000000   5579690   5579690  \n",
              "8516           0           0         0.0      0.000000         0         0  \n",
              "5975           0           0         0.0      0.000000         0         0  \n",
              "8257      149382       30864  10000000.0   5323.588504  10000000   9999989  \n",
              "6007           0           0         0.0      0.000000         0         0  \n",
              "...          ...         ...         ...           ...       ...       ...  \n",
              "1493         379         379  99700000.0      0.000000  99700000  99700000  \n",
              "8519     2480012       23193  10000000.0  18207.349450  10000000   9968005  \n",
              "3302           0           0         0.0      0.000000         0         0  \n",
              "3988           0           0         0.0      0.000000         0         0  \n",
              "4873           0           0         0.0      0.000000         0         0  \n",
              "\n",
              "[18000 rows x 78 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14840b18-4792-4e6e-9560-d0df76bfd52a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>...</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1191</th>\n",
              "      <td>443</td>\n",
              "      <td>5735211.0</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>350</td>\n",
              "      <td>4867</td>\n",
              "      <td>193</td>\n",
              "      <td>0</td>\n",
              "      <td>38.888889</td>\n",
              "      <td>71.129186</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>32.0</td>\n",
              "      <td>155518.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>155518</td>\n",
              "      <td>155518</td>\n",
              "      <td>5579690.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5579690</td>\n",
              "      <td>5579690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8516</th>\n",
              "      <td>53</td>\n",
              "      <td>50299.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>204</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5975</th>\n",
              "      <td>53</td>\n",
              "      <td>26691.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>158</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8257</th>\n",
              "      <td>443</td>\n",
              "      <td>115409745.0</td>\n",
              "      <td>44</td>\n",
              "      <td>57</td>\n",
              "      <td>743</td>\n",
              "      <td>76082</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>16.886364</td>\n",
              "      <td>64.409741</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>32.0</td>\n",
              "      <td>42871.27273</td>\n",
              "      <td>35355.2571</td>\n",
              "      <td>149382</td>\n",
              "      <td>30864</td>\n",
              "      <td>10000000.0</td>\n",
              "      <td>5323.588504</td>\n",
              "      <td>10000000</td>\n",
              "      <td>9999989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6007</th>\n",
              "      <td>53</td>\n",
              "      <td>48366.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>93</td>\n",
              "      <td>55</td>\n",
              "      <td>55</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493</th>\n",
              "      <td>80</td>\n",
              "      <td>99765580.0</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>368</td>\n",
              "      <td>11595</td>\n",
              "      <td>368</td>\n",
              "      <td>0</td>\n",
              "      <td>52.571429</td>\n",
              "      <td>139.090926</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>379.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>379</td>\n",
              "      <td>379</td>\n",
              "      <td>99700000.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>99700000</td>\n",
              "      <td>99700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8519</th>\n",
              "      <td>443</td>\n",
              "      <td>113153586.0</td>\n",
              "      <td>40</td>\n",
              "      <td>44</td>\n",
              "      <td>1628</td>\n",
              "      <td>47059</td>\n",
              "      <td>336</td>\n",
              "      <td>0</td>\n",
              "      <td>40.700000</td>\n",
              "      <td>103.236398</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>32.0</td>\n",
              "      <td>268192.09090</td>\n",
              "      <td>736552.1540</td>\n",
              "      <td>2480012</td>\n",
              "      <td>23193</td>\n",
              "      <td>10000000.0</td>\n",
              "      <td>18207.349450</td>\n",
              "      <td>10000000</td>\n",
              "      <td>9968005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3302</th>\n",
              "      <td>53</td>\n",
              "      <td>169.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>206</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3988</th>\n",
              "      <td>443</td>\n",
              "      <td>136364.0</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>847</td>\n",
              "      <td>8831</td>\n",
              "      <td>373</td>\n",
              "      <td>0</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>116.258829</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4873</th>\n",
              "      <td>52188</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18000 rows × 78 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14840b18-4792-4e6e-9560-d0df76bfd52a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14840b18-4792-4e6e-9560-d0df76bfd52a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14840b18-4792-4e6e-9560-d0df76bfd52a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_1 = y_train[:3000]\n",
        "y_train_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE0op-__AAwo",
        "outputId": "a4e1eec1-c271-4026-ce52-a199881b19c3"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_1 = X_train.iloc[:3000]\n",
        "X_train_2 = X_train.iloc[3000:6000]\n",
        "X_train_3 = X_train.iloc[6000:]\n",
        "y_train_1 = y_train[:3000]\n",
        "y_train_2 = y_train[3000:6000]\n",
        "y_train_3 = y_train[6000:]"
      ],
      "metadata": {
        "id": "1GuldLlMQdtI"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=2)\n",
        "kf.get_n_splits(X)\n",
        "print(kf)\n",
        "KFold(n_splits=2, random_state=None, shuffle=False)\n",
        "for train_index, test_index in kf.split(X):\n",
        "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "id": "SHqGaAAFRNCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae0ed8c-b3b9-4af7-e2e0-0a002e0f9a92"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KFold(n_splits=2, random_state=None, shuffle=False)\n",
            "TRAIN: [10000 10001 10002 ... 19997 19998 19999] TEST: [   0    1    2 ... 9997 9998 9999]\n",
            "TRAIN: [   0    1    2 ... 9997 9998 9999] TEST: [10000 10001 10002 ... 19997 19998 19999]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf']} \n",
        "  \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "\n",
        "y_train_1=y_train_1.ravel();\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train_1, y_train_1)"
      ],
      "metadata": {
        "id": "TGINrCiNUIzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "026b3fc4-8c92-42e9-d035-9149a161ddae"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.852 total time=   2.1s\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.853 total time=   2.5s\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.853 total time=   3.4s\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.852 total time=   3.7s\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.850 total time=   3.6s\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.852 total time=   3.8s\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.853 total time=   3.6s\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.853 total time=   2.1s\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.852 total time=   2.0s\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.850 total time=   2.0s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.852 total time=   2.0s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.853 total time=   2.0s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.853 total time=   2.0s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.852 total time=   2.0s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.850 total time=   2.0s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.860 total time=   2.0s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.860 total time=   2.0s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.855 total time=   2.0s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.853 total time=   2.1s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.860 total time=   2.0s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.862 total time=   2.1s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.863 total time=   2.0s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   2.0s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.862 total time=   2.0s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.860 total time=   2.0s\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.865 total time=   3.6s\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.867 total time=   3.5s\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.880 total time=   3.7s\n",
            "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.868 total time=   3.7s\n",
            "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.867 total time=   3.7s\n",
            "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.865 total time=   3.5s\n",
            "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.867 total time=   3.5s\n",
            "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.880 total time=   3.7s\n",
            "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.868 total time=   3.7s\n",
            "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.867 total time=   4.1s\n",
            "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.865 total time=   3.8s\n",
            "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.867 total time=   3.5s\n",
            "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.882 total time=   3.7s\n",
            "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.868 total time=   3.7s\n",
            "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.868 total time=   3.7s\n",
            "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.868 total time=   3.5s\n",
            "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.868 total time=   3.5s\n",
            "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.883 total time=   3.7s\n",
            "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.872 total time=   3.7s\n",
            "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.870 total time=   3.7s\n",
            "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   3.4s\n",
            "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.870 total time=   3.5s\n",
            "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.888 total time=   3.7s\n",
            "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.872 total time=   3.7s\n",
            "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.870 total time=   3.6s\n",
            "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.865 total time=   3.8s\n",
            "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.867 total time=   3.7s\n",
            "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.880 total time=   3.7s\n",
            "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.868 total time=   3.7s\n",
            "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.867 total time=   3.8s\n",
            "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.865 total time=   3.8s\n",
            "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.867 total time=   3.8s\n",
            "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.880 total time=   3.8s\n",
            "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.868 total time=   3.8s\n",
            "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.867 total time=   3.8s\n",
            "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.867 total time=   3.8s\n",
            "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.868 total time=   3.8s\n",
            "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.882 total time=   3.7s\n",
            "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.870 total time=   3.8s\n",
            "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.870 total time=   3.8s\n",
            "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.868 total time=   3.8s\n",
            "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.868 total time=   3.8s\n",
            "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.887 total time=   3.8s\n",
            "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.872 total time=   3.8s\n",
            "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.870 total time=   3.9s\n",
            "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.868 total time=   3.9s\n",
            "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.870 total time=   3.9s\n",
            "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.888 total time=   3.9s\n",
            "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.872 total time=   3.9s\n",
            "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.870 total time=   3.9s\n",
            "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.865 total time=   3.9s\n",
            "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.867 total time=   3.8s\n",
            "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.880 total time=   3.8s\n",
            "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.868 total time=   3.8s\n",
            "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.867 total time=   3.9s\n",
            "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.865 total time=   3.8s\n",
            "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.867 total time=   3.9s\n",
            "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.880 total time=   3.8s\n",
            "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.868 total time=   3.8s\n",
            "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.867 total time=   3.8s\n",
            "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.867 total time=   5.7s\n",
            "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.868 total time=   5.2s\n",
            "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.882 total time=   3.7s\n",
            "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.870 total time=   3.8s\n",
            "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.870 total time=   3.8s\n",
            "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.868 total time=   3.8s\n",
            "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.868 total time=   3.8s\n",
            "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.887 total time=   3.8s\n",
            "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.872 total time=   3.7s\n",
            "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.870 total time=   3.8s\n",
            "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.868 total time=   3.9s\n",
            "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.870 total time=   3.7s\n",
            "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.888 total time=   3.7s\n",
            "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.872 total time=   3.8s\n",
            "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.870 total time=   3.7s\n",
            "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.865 total time=   3.8s\n",
            "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.867 total time=   3.8s\n",
            "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.880 total time=   3.8s\n",
            "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.868 total time=   3.7s\n",
            "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.867 total time=   3.8s\n",
            "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.865 total time=   3.8s\n",
            "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.867 total time=   3.8s\n",
            "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.880 total time=   3.7s\n",
            "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.868 total time=   3.7s\n",
            "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.867 total time=   3.8s\n",
            "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.867 total time=   3.7s\n",
            "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.868 total time=   3.7s\n",
            "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.882 total time=   3.7s\n",
            "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.870 total time=   3.7s\n",
            "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.870 total time=   3.8s\n",
            "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.868 total time=   3.9s\n",
            "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.868 total time=   3.8s\n",
            "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.887 total time=   3.8s\n",
            "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.872 total time=   3.8s\n",
            "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.870 total time=   3.8s\n",
            "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.868 total time=   3.8s\n",
            "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.870 total time=   3.8s\n",
            "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.888 total time=   3.8s\n",
            "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.872 total time=   3.9s\n",
            "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.870 total time=   3.8s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['rbf']},\n",
              "             verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "grid_vals = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1]}\n",
        "grid_lr = GridSearchCV(estimator=model, param_grid=grid_vals, \n",
        "scoring='accuracy', cv=6, refit=True, return_train_score=True) \n",
        "#Training and Prediction\n",
        "grid_lr.fit(X_train, y_train)\n",
        "preds = grid_lr.best_estimator_.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMnYiJ8iB-5E",
        "outputId": "2de4759c-9d13-4333-e743-f080dec03041"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=6.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "24 fits failed out of a total of 48.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.86550019        nan 0.91080013        nan 0.91409983\n",
            "        nan 0.94140062]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [       nan 0.86562001        nan 0.91084001        nan 0.91411999\n",
            "        nan 0.94372003]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False)\n",
        "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "clf.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e_Gq5HQEJNF",
        "outputId": "60b43e72-7ecb-491b-d1f8-9f1e8871b349"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=2, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import NuSVC\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "import numpy as np\n",
        "#Initializing Support Vector classifier\n",
        "classifier1 = SVC(C = 50, degree = 1, gamma = \"auto\", kernel = \"rbf\", probability = True)\n",
        "# Initializing Multi-layer perceptron classifier\n",
        "classifier2 = MLPClassifier(activation = \"relu\", alpha = 0.1, hidden_layer_sizes = (10,10,10), learning_rate = \"constant\", max_iter = 2000, random_state = 1000)\n",
        "# Initialing Nu Support Vector classifier\n",
        "classifier3 = NuSVC(degree = 1, kernel = \"rbf\", nu = 0.25, probability = True)\n",
        "# Initializing Random Forest classifier\n",
        "classifier4 = RandomForestClassifier(n_estimators = 500, criterion = \"gini\", max_depth = 10,max_features = \"auto\", min_samples_leaf = 0.005,\n",
        "min_samples_split = 0.005, n_jobs = -1, random_state = 1000)\n",
        "# Initializing the StackingCV classifier\n",
        "sclf = StackingCVClassifier(classifiers = [classifier1, classifier2, classifier3, classifier4],shuffle = False,use_probas = True,cv = 5,meta_classifier = SVC(probability = True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "bw29qiXHMZdM",
        "outputId": "c73d2164-33c2-4fff-98ff-68d54b8d0835"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-e45b8923d155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackingCVClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Initializing Support Vector classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlxtend/classifier/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mensemble_vote\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnsembleVoteClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstacking_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstacking_cv_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackingCVClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m __all__ = [\"Perceptron\", \"Adaline\",\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mlxtend/classifier/stacking_cv_classification.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'six' from 'sklearn.externals' (/usr/local/lib/python3.7/dist-packages/sklearn/externals/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "estimators = [\n",
        "('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
        "('svr', make_pipeline(StandardScaler(),\n",
        "LinearSVC(random_state=42)))\n",
        "]\n",
        "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())"
      ],
      "metadata": {
        "id": "VbjcjR6bP1mQ"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "#Instantiate and fit the RandomForestClassifier\n",
        "forest = RandomForestClassifier()\n",
        "forest.fit(X_train, y_train)\n",
        "# Make predictions for the test set\n",
        "y_pred_test = forest.predict(X_test)\n",
        "# View confusion matrix for test data and predictions\n",
        "metrics.confusion_matrix(y_test, y_pred_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGZ7x523TVvG",
        "outputId": "af955c3b-5a34-4caa-e6cb-93716b0f0b90"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8507,    0,    0,    1,    5,    0,    0,    3,    0,    0,    0],\n",
              "       [  10,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [   3,    0,   47,    0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [   4,    0,    0,  968,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [   4,    0,    0,    0,   15,    1,    0,    0,    0,    0,    0],\n",
              "       [   2,    0,    0,    0,    2,   20,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,   27,    0,    0,    0,    0],\n",
              "       [   1,    0,    0,    0,    0,    0,    0,  346,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,   26,    0,    0],\n",
              "       [   3,    0,    0,    0,    0,    0,    0,    0,    0,    4,    0],\n",
              "       [   1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf_en = DecisionTreeClassifier(criterion='entropy',max_depth=3, \n",
        "random_state=0)\n",
        "clf_en.fit(X_train, y_train)\n",
        "y_pred_en = clf_en.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred_en)\n",
        "print('Confusion matrix\\n\\n', cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKFlZMVuVGfJ",
        "outputId": "2b3dc00d-e794-4f45-f5a1-509f10846a3a"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix\n",
            "\n",
            " [[8347    0    1   10    0    0    0  158    0    0    0]\n",
            " [   8    0    0    0    0    0    0    2    0    0    0]\n",
            " [  16    0   34    0    0    0    0    0    0    0    0]\n",
            " [ 307    0    0  665    0    0    0    0    0    0    0]\n",
            " [  20    0    0    0    0    0    0    0    0    0    0]\n",
            " [  24    0    0    0    0    0    0    0    0    0    0]\n",
            " [  27    0    0    0    0    0    0    0    0    0    0]\n",
            " [   2    0    0    0    0    0    0  345    0    0    0]\n",
            " [  26    0    0    0    0    0    0    0    0    0    0]\n",
            " [   7    0    0    0    0    0    0    0    0    0    0]\n",
            " [   1    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "# Init classifier\n",
        "xgb_cl = xgb.XGBClassifier()\n",
        "# Fit\n",
        "xgb_cl.fit(X_train, y_train)\n",
        "# Predict\n",
        "preds = xgb_cl.predict(X_test)\n",
        "# Score\n",
        "accuracy_score(y_test, preds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OngFWT3VOOM",
        "outputId": "832a4e5c-2ad1-40be-8db9-a1e288c99bb2"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9969"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate data\n",
        "trainX, trainy, testX, testy = X_train,y_train,X_test,y_test\n",
        "# fit model\n",
        "model = model.fit(trainX, trainy)\n",
        "\n",
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(testX)#, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = model.predict_classes(testX)#, verbose=0)\n",
        "\n",
        "# reduce to 1d array\n",
        "yhat_probs = yhat_probs[:, 0]\n",
        "yhat_classes = yhat_classes[:, 0]\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(testy, yhat_classes)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(testy, yhat_classes)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(testy, yhat_classes)\n",
        "print('F1 score: %f' % f1)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(testy, yhat_probs)\n",
        "print('ROC AUC: %f' % auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "wqvwgTONVc6y",
        "outputId": "8020a418-0e40-43c6-94fb-f3e826671d94"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-157-de865a6d6dd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0myhat_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# predict crisp classes for test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0myhat_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# reduce to 1d array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'predict_classes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "# Generate the Tree explainer and SHAP values\n",
        "explainer = shap.TreeExplainer(xgb_mod)\n",
        "shap_values = explainer.shap_values(X)\n",
        "expected_value = explainer.expected_value\n",
        "# Generate summary bar plot \n",
        "shap.summary_plot(shap_values, X,plot_type=\"bar\") \n",
        "# Generate dependence plot\n",
        "shap.dependence_plot(\"worst concave points\", shap_values, X, interaction_index=\"mean concave points\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "xn-fowqGZ3I7",
        "outputId": "79864e4f-d799-40a6-f3db-8a91a0ebec4b"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-684b28cbaade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Generate the Tree explainer and SHAP values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_mod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexpected_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}